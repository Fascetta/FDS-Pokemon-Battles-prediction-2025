{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d077c172",
   "metadata": {
    "papermill": {
     "duration": 0.006701,
     "end_time": "2025-11-13T17:52:39.273308",
     "exception": false,
     "start_time": "2025-11-13T17:52:39.266607",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# FDS Challenge Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57551ef",
   "metadata": {
    "papermill": {
     "duration": 0.004382,
     "end_time": "2025-11-13T17:52:39.283220",
     "exception": false,
     "start_time": "2025-11-13T17:52:39.278838",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 0. Version Summary\n",
    "\n",
    "This version approaches the problem by focusing on move level features, specifically by calculating the expected damage of each move and tracking the available status conditions for the Pokèmon. It also includes cumulative features, such as mean and variance, to predict imbalances between the teams.\n",
    "\n",
    "This notebook includes evaluation of single models, which we then decided to stack using the StackingClassifier, obtaining better scores than single models. The approach focuses on gradient-boost like algorithms, with LogisticRegression as final estimator. This version also includes a trial of CalibratedClassifier, which we evaluated, given that it could increase metrics via predicted probabilities.\n",
    "\n",
    "Each model in the StackingClassifier was tuned using HalvingGridSearch, an experimental hyperparameter tuning strategy. This was chosen because it yielded better results than RandomizedSearch, and is significantly faster than GridSearch.\n",
    "\n",
    "This version evaluates PCA on the dataset before training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46950fac",
   "metadata": {
    "papermill": {
     "duration": 0.004273,
     "end_time": "2025-11-13T17:52:39.291913",
     "exception": false,
     "start_time": "2025-11-13T17:52:39.287640",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475c3842",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T17:52:39.302398Z",
     "iopub.status.busy": "2025-11-13T17:52:39.302130Z",
     "iopub.status.idle": "2025-11-13T17:52:52.560626Z",
     "shell.execute_reply": "2025-11-13T17:52:52.559804Z"
    },
    "papermill": {
     "duration": 13.265705,
     "end_time": "2025-11-13T17:52:52.562117",
     "exception": false,
     "start_time": "2025-11-13T17:52:39.296412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- Define the path to our data ---\n",
    "COMPETITION_NAME = 'fds-pokemon-battles-prediction-2025'\n",
    "DATA_PATH = os.path.join('../input', COMPETITION_NAME)\n",
    "train_file_path = os.path.join(DATA_PATH, 'train.jsonl')\n",
    "test_file_path = os.path.join(DATA_PATH, 'test.jsonl')\n",
    "\n",
    "def load_data(file_path):\n",
    "    data = []\n",
    "    print(f\"Loading data from '{file_path}'...\")\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            for line in f:\n",
    "                data.append(json.loads(line))\n",
    "        print(f\"Successfully loaded {len(data)} battles.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: Could not find the file at '{file_path}'.\")\n",
    "    return data\n",
    "\n",
    "train_data = load_data(train_file_path)\n",
    "test_data = load_data(test_file_path) # Load the test data as well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ac0a0c",
   "metadata": {
    "papermill": {
     "duration": 0.004316,
     "end_time": "2025-11-13T17:52:52.571474",
     "exception": false,
     "start_time": "2025-11-13T17:52:52.567158",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Complete Pokèmon Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f51b294",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T17:52:52.581697Z",
     "iopub.status.busy": "2025-11-13T17:52:52.581321Z",
     "iopub.status.idle": "2025-11-13T17:52:52.610304Z",
     "shell.execute_reply": "2025-11-13T17:52:52.609272Z"
    },
    "papermill": {
     "duration": 0.035844,
     "end_time": "2025-11-13T17:52:52.611668",
     "exception": false,
     "start_time": "2025-11-13T17:52:52.575824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Gen 1 types in lowercase\n",
    "types = [\n",
    "    \"normal\", \"fire\", \"water\", \"electric\", \"grass\", \"ice\", \"fighting\", \"poison\",\n",
    "    \"ground\", \"flying\", \"psychic\", \"bug\", \"rock\", \"ghost\", \"dragon\", \"notype\",\n",
    "]\n",
    "\n",
    "# Type effectiveness values\n",
    "type_chart = {\n",
    "    \"normal\":   {\"rock\": 0.5, \"ghost\": 0.0},\n",
    "    \"fire\":     {\"grass\": 2.0, \"ice\": 2.0, \"bug\": 2.0, \"rock\": 0.5, \"fire\": 0.5, \"water\": 0.5},\n",
    "    \"water\":    {\"fire\": 2.0, \"ground\": 2.0, \"rock\": 2.0, \"water\": 0.5, \"grass\": 0.5},\n",
    "    \"electric\": {\"water\": 2.0, \"flying\": 2.0, \"electric\": 0.5, \"grass\": 0.5, \"ground\": 0.0},\n",
    "    \"grass\":    {\"water\": 2.0, \"ground\": 2.0, \"rock\": 2.0, \"fire\": 0.5, \"grass\": 0.5, \"flying\": 0.5, \"bug\": 0.5},\n",
    "    \"ice\":      {\"grass\": 2.0, \"ground\": 2.0, \"flying\": 2.0, \"dragon\": 2.0, \"fire\": 0.5, \"water\": 0.5},\n",
    "    \"fighting\": {\"normal\": 2.0, \"rock\": 2.0, \"ice\": 2.0, \"bug\": 0.5, \"psychic\": 0.5, \"ghost\": 0.0},\n",
    "    \"poison\":   {\"grass\": 2.0, \"bug\": 2.0, \"poison\": 0.5, \"ground\": 0.5, \"rock\": 0.5, \"ghost\": 0.5},\n",
    "    \"ground\":   {\"fire\": 2.0, \"electric\": 2.0, \"poison\": 2.0, \"rock\": 2.0, \"bug\": 0.5, \"flying\": 0.0},\n",
    "    \"flying\":   {\"grass\": 2.0, \"fighting\": 2.0, \"bug\": 2.0, \"electric\": 0.5, \"rock\": 0.5},\n",
    "    \"psychic\":  {\"fighting\": 2.0, \"poison\": 2.0, \"psychic\": 0.5},\n",
    "    \"bug\":      {\"grass\": 2.0, \"poison\": 2.0, \"psychic\": 2.0, \"fire\": 0.5, \"fighting\": 0.5, \"flying\": 0.5, \"ghost\": 0.5},\n",
    "    \"rock\":     {\"fire\": 2.0, \"ice\": 2.0, \"flying\": 2.0, \"bug\": 2.0, \"fighting\": 0.5, \"ground\": 0.5},\n",
    "    \"ghost\":    {\"psychic\": 0.0, \"ghost\": 2.0, \"normal\": 0.0},\n",
    "    \"dragon\":   {\"dragon\": 2.0},\n",
    "    \"notype\":   {}\n",
    "}\n",
    "\n",
    "# Create full chart with default 1.0 (neutral)\n",
    "df_typechart = pd.DataFrame(index=types, columns=types).fillna(1.0)\n",
    "\n",
    "# Apply effectiveness values\n",
    "for attacker, defenders in type_chart.items():\n",
    "    for defender, value in defenders.items():\n",
    "        df_typechart.loc[attacker, defender] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a15d45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T17:52:52.623003Z",
     "iopub.status.busy": "2025-11-13T17:52:52.622678Z",
     "iopub.status.idle": "2025-11-13T17:52:52.637391Z",
     "shell.execute_reply": "2025-11-13T17:52:52.636313Z"
    },
    "papermill": {
     "duration": 0.021513,
     "end_time": "2025-11-13T17:52:52.638853",
     "exception": false,
     "start_time": "2025-11-13T17:52:52.617340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df_typechart.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cecba1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T17:52:52.651683Z",
     "iopub.status.busy": "2025-11-13T17:52:52.651411Z",
     "iopub.status.idle": "2025-11-13T17:52:52.667975Z",
     "shell.execute_reply": "2025-11-13T17:52:52.666852Z"
    },
    "papermill": {
     "duration": 0.025527,
     "end_time": "2025-11-13T17:52:52.669577",
     "exception": false,
     "start_time": "2025-11-13T17:52:52.644050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def extract_unique_pokemon_no_ids(jsonl_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extracts a clean list of unique Pokémon with full base stats from the dataset.\n",
    "    - Includes Pokémon from p1_team_details, p2_lead_details, and p2_pokemon_state.\n",
    "    - Removes rows with all-zero stats if the Pokémon appears elsewhere with valid stats.\n",
    "    - Removes duplicates across battles: only one row per Pokémon name.\n",
    "    - Drops battle_id column.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            battle = json.loads(line)\n",
    "\n",
    "            # --- p1 team Pokémon ---\n",
    "            for p in battle.get(\"p1_team_details\", []):\n",
    "                rows.append({\n",
    "                    \"name\": p.get(\"name\", \"unknown\"),\n",
    "                    \"base_hp\": p.get(\"base_hp\", 0),\n",
    "                    \"base_atk\": p.get(\"base_atk\", 0),\n",
    "                    \"base_def\": p.get(\"base_def\", 0),\n",
    "                    \"base_spa\": p.get(\"base_spa\", 0),\n",
    "                    \"base_spd\": p.get(\"base_spd\", 0),\n",
    "                    \"base_spe\": p.get(\"base_spe\", 0),\n",
    "                    \"type_1\": p.get(\"types\", \"notype\")[0],\n",
    "                    \"type_2\": p.get(\"types\", \"notype\")[1],\n",
    "                    \"lvl\": p.get(\"level\", 0),\n",
    "                    \"hp\": (2 * p.get(\"base_hp\", 0)) + 100 + 10,\n",
    "                    \"atk\": (2 * p.get(\"base_atk\", 0)) + 5,\n",
    "                    \"def\": (2 * p.get(\"base_def\", 0)) + 5,\n",
    "                    \"spa\": (2 * p.get(\"base_spa\", 0)) + 5,\n",
    "                    \"spd\": (2 * p.get(\"base_spd\", 0)) + 5,\n",
    "                    \"spe\": (2 * p.get(\"base_spe\", 0)) + 5,\n",
    "                })\n",
    "\n",
    "            # --- p2 lead details ---\n",
    "            lead_details = battle.get(\"p2_lead_details\")\n",
    "            if lead_details:\n",
    "                rows.append({\n",
    "                    \"name\": lead_details.get(\"name\", \"unknown\"),\n",
    "                    \"base_hp\": lead_details.get(\"base_hp\", 0),\n",
    "                    \"base_atk\": lead_details.get(\"base_atk\", 0),\n",
    "                    \"base_def\": lead_details.get(\"base_def\", 0),\n",
    "                    \"base_spa\": lead_details.get(\"base_spa\", 0),\n",
    "                    \"base_spd\": lead_details.get(\"base_spd\", 0),\n",
    "                    \"base_spe\": lead_details.get(\"base_spe\", 0),\n",
    "                    \"type_1\": lead_details.get(\"types\", \"notype\")[0],\n",
    "                    \"type_2\": lead_details.get(\"types\", \"notype\")[1],\n",
    "                    \"lvl\": lead_details.get(\"level\", 0),\n",
    "\n",
    "                    # Full stats at level 100 with no IVs/EVs (https://www.pokemaniablog.com/2017/11/11/CalculatingHP.html)\n",
    "                    \"hp\" : (2 * lead_details.get(\"base_hp\", 0)) + 100 + 10,\n",
    "                    \"atk\": (2 * lead_details.get(\"base_atk\", 0)) + 5,\n",
    "                    \"def\": (2 * lead_details.get(\"base_def\", 0)) + 5,\n",
    "                    \"spa\": (2 * lead_details.get(\"base_spa\", 0)) + 5,\n",
    "                    \"spd\": (2 * lead_details.get(\"base_spd\", 0)) + 5,\n",
    "                    \"spe\": (2 * lead_details.get(\"base_spe\", 0)) + 5,\n",
    "                })\n",
    "\n",
    "            # --- p2 team Pokémon from timeline (unique per battle) ---\n",
    "            seen = set()\n",
    "            for turn in battle.get(\"battle_timeline\", []):\n",
    "                p2 = turn.get(\"p2_pokemon_state\")\n",
    "                if not p2:\n",
    "                    continue\n",
    "                name = p2.get(\"name\", \"unknown\")\n",
    "                if name in seen:\n",
    "                    continue\n",
    "                seen.add(name)\n",
    "                rows.append({\n",
    "                    \"name\": name,\n",
    "                    \"base_hp\": p2.get(\"base_hp\", 0),\n",
    "                    \"base_atk\": p2.get(\"base_atk\", 0),\n",
    "                    \"base_def\": p2.get(\"base_def\", 0),\n",
    "                    \"base_spa\": p2.get(\"base_spa\", 0),\n",
    "                    \"base_spd\": p2.get(\"base_spd\", 0),\n",
    "                    \"base_spe\": p2.get(\"base_spe\", 0),\n",
    "                    \"type_1\": p2.get(\"types\", \"notype\")[0],\n",
    "                    \"type_2\": p2.get(\"types\", \"notype\")[1],\n",
    "                    \"lvl\": p2.get(\"level\", 0),\n",
    "\n",
    "                    # Full stats at level 100 with no IVs/EVs (https://www.pokemaniablog.com/2017/11/11/CalculatingHP.html)\n",
    "                    \"hp\": (2 * p2.get(\"base_hp\", 0)) + 100 + 10,\n",
    "                    \"atk\": (2 * p2.get(\"base_atk\", 0)) + 5,\n",
    "                    \"def\": (2 * p2.get(\"base_def\", 0)) + 5,\n",
    "                    \"spa\": (2 * p2.get(\"base_spa\", 0)) + 5,\n",
    "                    \"spd\": (2 * p2.get(\"base_spd\", 0)) + 5,\n",
    "                    \"spe\": (2 * p2.get(\"base_spe\", 0)) + 5,\n",
    "                })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    # --- Remove zero-stat rows if name appears elsewhere with valid stats ---\n",
    "    stat_cols = [\"base_hp\", \"base_atk\", \"base_def\", \"base_spa\", \"base_spd\", \"base_spe\", \"lvl\"]\n",
    "    zero_mask = (df[stat_cols] == 0).all(axis=1)\n",
    "    valid_names = set(df.loc[~zero_mask, \"name\"])\n",
    "    df = df.loc[~(zero_mask & df[\"name\"].isin(valid_names))]\n",
    "\n",
    "    # --- Drop duplicates: keep only one row per Pokémon name ---\n",
    "    df = df.drop_duplicates(subset=[\"name\"], keep=\"first\").reset_index(drop=True)\n",
    "    \n",
    "    def normalize_levels(df):\n",
    "        def flatten_levels(x):\n",
    "            if isinstance(x, tuple):\n",
    "                return list(x)\n",
    "            elif isinstance(x, list):\n",
    "                return x\n",
    "            else:\n",
    "                return [x]  # single int\n",
    "    \n",
    "        df = df.copy()\n",
    "        df[\"lvl\"] = df[\"lvl\"].apply(flatten_levels)\n",
    "        return df.explode(\"lvl\").astype({\"lvl\": int})\n",
    "\n",
    "    clean_df = normalize_levels(df)\n",
    "\n",
    "    merged_df = (\n",
    "        clean_df.groupby(\"name\", as_index=False)\n",
    "        .agg({\n",
    "            \"base_hp\": \"max\",\n",
    "            \"base_atk\": \"max\",\n",
    "            \"base_def\": \"max\",\n",
    "            \"base_spa\": \"max\",\n",
    "            \"base_spd\": \"max\",\n",
    "            \"base_spe\": \"max\",\n",
    "            \"type_1\": \"first\",\n",
    "            \"type_2\": \"first\",\n",
    "            \"lvl\": \"max\", # Keep the highest level if multiple levels exist\n",
    "            \"hp\": \"max\",\n",
    "            \"atk\": \"max\",\n",
    "            \"def\": \"max\",\n",
    "            \"spa\": \"max\",\n",
    "            \"spd\": \"max\",\n",
    "            \"spe\": \"max\",\n",
    "        })\n",
    "    )\n",
    "\n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60944cfc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T17:52:52.680677Z",
     "iopub.status.busy": "2025-11-13T17:52:52.680394Z",
     "iopub.status.idle": "2025-11-13T17:52:55.195113Z",
     "shell.execute_reply": "2025-11-13T17:52:55.193576Z"
    },
    "papermill": {
     "duration": 2.522608,
     "end_time": "2025-11-13T17:52:55.197207",
     "exception": false,
     "start_time": "2025-11-13T17:52:52.674599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pokemon_df_train = extract_unique_pokemon_no_ids(train_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c1b97d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T17:52:55.208425Z",
     "iopub.status.busy": "2025-11-13T17:52:55.208141Z",
     "iopub.status.idle": "2025-11-13T17:52:55.217687Z",
     "shell.execute_reply": "2025-11-13T17:52:55.216171Z"
    },
    "papermill": {
     "duration": 0.016364,
     "end_time": "2025-11-13T17:52:55.218879",
     "exception": false,
     "start_time": "2025-11-13T17:52:55.202515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\n All Pokémon entries:\")\n",
    "display(pokemon_df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ce2365",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T17:52:55.230001Z",
     "iopub.status.busy": "2025-11-13T17:52:55.229729Z",
     "iopub.status.idle": "2025-11-13T17:52:55.236503Z",
     "shell.execute_reply": "2025-11-13T17:52:55.235425Z"
    },
    "papermill": {
     "duration": 0.014079,
     "end_time": "2025-11-13T17:52:55.238242",
     "exception": false,
     "start_time": "2025-11-13T17:52:55.224163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_triggered_statuses(jsonl_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extracts status conditions triggered during battles from the dataset.\n",
    "    - For each turn, checks the 'status' field of p1 and p2 pokemon_state.\n",
    "    - Records battle_id, turn number, player (p1 or p2), and status condition.\n",
    "    \"\"\"\n",
    "    data = set()\n",
    "\n",
    "    with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            battle = json.loads(line)\n",
    "            timeline = battle.get(\"battle_timeline\", [])\n",
    "\n",
    "            for turn in timeline:\n",
    "                for player_key in [\"p1\", \"p2\"]:\n",
    "                    pokemon_state = turn.get(f\"{player_key}_pokemon_state\", {})\n",
    "                    status = pokemon_state.get(\"status\")\n",
    "\n",
    "                    if status != 'nostatus' and status is not None:\n",
    "                        data.add(status)\n",
    "\n",
    "    return list(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cd130d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T17:52:55.251825Z",
     "iopub.status.busy": "2025-11-13T17:52:55.250784Z",
     "iopub.status.idle": "2025-11-13T17:52:56.977604Z",
     "shell.execute_reply": "2025-11-13T17:52:56.976565Z"
    },
    "papermill": {
     "duration": 1.734667,
     "end_time": "2025-11-13T17:52:56.978995",
     "exception": false,
     "start_time": "2025-11-13T17:52:55.244328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "available_status = extract_triggered_statuses(train_file_path)\n",
    "print(\"\\n Extracted Status Conditions:\")\n",
    "print(available_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a416dd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T17:52:58.892638Z",
     "iopub.status.busy": "2025-11-13T17:52:58.892341Z",
     "iopub.status.idle": "2025-11-13T17:52:58.915912Z",
     "shell.execute_reply": "2025-11-13T17:52:58.915216Z"
    },
    "papermill": {
     "duration": 0.030977,
     "end_time": "2025-11-13T17:52:58.917139",
     "exception": false,
     "start_time": "2025-11-13T17:52:58.886162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def make_moves_df(jsonl_path: str, pokemon_df: pd.DataFrame, typechart: pd.DataFrame, verbose: bool) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Processes battle data to create a DataFrame of moves with calculated features.\n",
    "    - For each turn in each battle, extracts move details for both players.\n",
    "    - Calculates expected damage based on move properties and Pokémon stats.\n",
    "    - Tracks other features such as type effectiveness, status conditions, and stat boosts.\n",
    "    \"\"\"\n",
    "\n",
    "    import json\n",
    "    import pandas as pd\n",
    "\n",
    "    move_rows = []\n",
    "\n",
    "    #Boosts and relative multipliers available for atk, def, spa, spd, spe\n",
    "    boost_multipliers = {\n",
    "        -6: 0.25,\n",
    "        -5: 0.28,\n",
    "        -4: 0.33,\n",
    "        -3: 0.4,\n",
    "        -2: 0.5,\n",
    "        -1: 0.66,\n",
    "        0: 1.0,\n",
    "        1: 1.5,\n",
    "        2: 2.0,\n",
    "        3: 2.5,\n",
    "        4: 3.0,\n",
    "        5: 3.5,\n",
    "        6: 4.0,\n",
    "    }\n",
    "\n",
    "    # Normalize Pokémon data\n",
    "    pokemon_df_copy = pokemon_df.copy()\n",
    "    pokemon_df_copy.columns = pokemon_df_copy.columns.str.lower().str.strip()\n",
    "\n",
    "    if \"name\" in pokemon_df_copy.columns:\n",
    "        pokemon_df_copy[\"name\"] = pokemon_df_copy[\"name\"].str.lower().str.strip()\n",
    "        pokemon_df_copy.set_index(\"name\", inplace=True)\n",
    "    else:\n",
    "        raise ValueError(f\"'name' column missing. Available columns: {pokemon_df_copy.columns.tolist()}\")\n",
    "\n",
    "    # Parse battles\n",
    "    with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            battle = json.loads(line)\n",
    "            battle_id = battle.get(\"battle_id\")\n",
    "            timeline = battle.get(\"battle_timeline\", [])\n",
    "\n",
    "            for turn_index, turn in enumerate(timeline):\n",
    "                turn_data = {}\n",
    "                turn_moves = []\n",
    "\n",
    "                for side in [\"p1\", \"p2\"]:\n",
    "                    opponent = \"p2\" if side == \"p1\" else \"p1\"\n",
    "                    move = turn.get(f\"{side}_move_details\")\n",
    "                    if not move:\n",
    "                        continue\n",
    "\n",
    "                    atk_boosts = turn.get(f\"{side}_pokemon_state\").get(\"boosts\", {\n",
    "                    \"atk\": 0,\n",
    "                    \"def\": 0,\n",
    "                    \"spa\": 0,\n",
    "                    \"spd\": 0,\n",
    "                    \"spe\": 0\n",
    "                })\n",
    "\n",
    "                    def_boosts = turn.get(f\"{opponent}_pokemon_state\").get(\"boosts\", {\n",
    "                    \"atk\": 0,\n",
    "                    \"def\": 0,\n",
    "                    \"spa\": 0,\n",
    "                    \"spd\": 0,\n",
    "                    \"spe\": 0\n",
    "                })\n",
    "\n",
    "                    atk_pk_name = turn.get(f\"{side}_pokemon_state\").get(\"name\").lower().strip()\n",
    "                    def_pk_name = turn.get(f\"{opponent}_pokemon_state\").get(\"name\").lower().strip()\n",
    "\n",
    "                    atk_spe = pokemon_df_copy.loc[atk_pk_name, \"spe\"]\n",
    "                    def_spe = pokemon_df_copy.loc[def_pk_name, \"spe\"]\n",
    "\n",
    "                    def_hp_pct = turn.get(f\"{opponent}_pokemon_state\").get(\"hp_pct\")\n",
    "\n",
    "                    def_t1 = pokemon_df_copy.loc[def_pk_name, \"type_1\"]\n",
    "                    def_t2 = pokemon_df_copy.loc[def_pk_name, \"type_2\"]\n",
    "                    def_stat = pokemon_df_copy.loc[def_pk_name, \"def\"] if move.get(\"category\").lower() == \"physical\" else pokemon_df_copy.loc[def_pk_name, \"spd\"]\n",
    "\n",
    "                    atk_t1 = pokemon_df_copy.loc[atk_pk_name, \"type_1\"]\n",
    "                    atk_t2 = pokemon_df_copy.loc[atk_pk_name, \"type_2\"]\n",
    "                    atk_stat = pokemon_df_copy.loc[atk_pk_name, \"atk\"] if move.get(\"category\").lower() == \"physical\" else pokemon_df_copy.loc[atk_pk_name, \"spa\"]\n",
    "\n",
    "                    \n",
    "                    if move.get(\"category\").lower() == \"physical\":\n",
    "                        def_stat = def_stat * boost_multipliers.get(def_boosts.get(\"def\"), 1.0)\n",
    "                        atk_stat = atk_stat * boost_multipliers.get(atk_boosts.get(\"atk\"), 1.0)\n",
    "                    elif move.get(\"category\").lower() == \"special\":\n",
    "                        def_stat = def_stat * boost_multipliers.get(def_boosts.get(\"spd\"), 1.0)\n",
    "                        atk_stat = atk_stat * boost_multipliers.get(atk_boosts.get(\"spa\"), 1.0)\n",
    "\n",
    "                    atk_spe = atk_spe * boost_multipliers.get(atk_boosts.get(\"spe\"), 1.0)\n",
    "                    def_spe = def_spe * boost_multipliers.get(def_boosts.get(\"spe\"), 1.0)\n",
    "\n",
    "                    if move.get(\"category\").lower() == \"physical\" and move.get(\"name\").lower() == \"reflect\":\n",
    "                        def_stat *= 2\n",
    "                    elif move.get(\"category\").lower() == \"special\" and move.get(\"name\").lower() == \"lightscreen\":\n",
    "                        def_stat *= 2\n",
    "\n",
    "                    if move.get(\"name\").lower() in [\"explosion\", \"selfdestruct\"]:\n",
    "                        def_stat = max(1, def_stat // 2)\n",
    "\n",
    "                    if atk_stat > 255 or def_stat > 255:\n",
    "                        atk_stat = math.floor(atk_stat / 4)\n",
    "                        def_stat = max(1, math.floor(def_stat / 4))\n",
    "                    \n",
    "                    move_mul = (typechart.loc[move.get(\"type\").lower(), def_t1] * \n",
    "                                typechart.loc[move.get(\"type\").lower(), def_t2]) if move.get(\"category\").lower() != \"status\" else 1.0\n",
    "\n",
    "                    turn_data[side] = {\n",
    "                        \"priority\": move.get(\"priority\", 0),\n",
    "                        \"speed\": atk_spe\n",
    "                    }\n",
    "\n",
    "                    turn_moves.append({\n",
    "                        \"battle_id\": battle_id,\n",
    "                        \"turn\": turn_index,\n",
    "                        \"attacker\": side,\n",
    "                        \"atk_pk\": atk_pk_name,\n",
    "                        \"atk_t1\": atk_t1,\n",
    "                        \"atk_t2\": atk_t2,\n",
    "                        \"name\": move.get(\"name\"),\n",
    "                        \"move_type\": move.get(\"type\").lower(),\n",
    "                        \"category\": move.get(\"category\").lower(),\n",
    "                        \"base_power\": move.get(\"base_power\"),\n",
    "                        \"accuracy\": move.get(\"accuracy\"),\n",
    "                        \"priority\": move.get(\"priority\"),\n",
    "                        \"defender\": opponent,\n",
    "                        \"def_pk\": def_pk_name,\n",
    "                        \"def_t1\": def_t1,\n",
    "                        \"def_t2\": def_t2,\n",
    "                        \"stab\": 1 if move.get(\"type\").lower() in [atk_t1, atk_t2] else 0,\n",
    "\n",
    "                        # Simplified damage formula from Bulbapedia (https://bulbapedia.bulbagarden.net/wiki/Damage#Damage_calculation)\n",
    "                        \"tot_damage\": 0.0 if move.get(\"category\").lower() == \"status\" else \n",
    "                                    ((((42 * move.get(\"base_power\", 0) * atk_stat / def_stat) / 50) + 2) *\n",
    "                                      (1.5 if move.get(\"type\").lower() in [atk_t1, atk_t2] else 1.0) *\n",
    "                                      move_mul * 0.925),  # average random factor 0.85-1.0\n",
    "                        \"se_move\": 1 if move_mul == 2.0 else 0,\n",
    "                        \"pe_move\": 1 if move_mul == 0.5 else 0,\n",
    "                        \"ne_move\": 1 if move_mul == 0.0 else 0,\n",
    "\n",
    "                        \"ko\": 1 if def_hp_pct == 0.0 else 0,\n",
    "                        \"def_status\": turn.get(f\"{opponent}_pokemon_state\").get(\"status\"),\n",
    "                        \"def_fnt\": 1 if turn.get(f\"{opponent}_pokemon_state\").get(\"status\") == \"fnt\" else 0,\n",
    "                        \"def_par\": 1 if turn.get(f\"{opponent}_pokemon_state\").get(\"status\") == \"par\" else 0,\n",
    "                        \"def_slp\": 1 if turn.get(f\"{opponent}_pokemon_state\").get(\"status\") == \"slp\" else 0,\n",
    "                        \"def_frz\": 1 if turn.get(f\"{opponent}_pokemon_state\").get(\"status\") == \"frz\" else 0,\n",
    "                        \"def_brn\": 1 if turn.get(f\"{opponent}_pokemon_state\").get(\"status\") == \"brn\" else 0,\n",
    "                        \"def_psn\": 1 if turn.get(f\"{opponent}_pokemon_state\").get(\"status\") == \"psn\" else 0,\n",
    "                        \"atk_status\": turn.get(f\"{side}_pokemon_state\").get(\"status\"),\n",
    "                        \"atk_fnt\": 1 if turn.get(f\"{side}_pokemon_state\").get(\"status\") == \"fnt\" else 0,\n",
    "                        \"atk_par\": 1 if turn.get(f\"{side}_pokemon_state\").get(\"status\") == \"par\" else 0,\n",
    "                        \"atk_slp\": 1 if turn.get(f\"{side}_pokemon_state\").get(\"status\") == \"slp\" else 0,\n",
    "                        \"atk_frz\": 1 if turn.get(f\"{side}_pokemon_state\").get(\"status\") == \"frz\" else 0,\n",
    "                        \"atk_brn\": 1 if turn.get(f\"{side}_pokemon_state\").get(\"status\") == \"brn\" else 0,\n",
    "                        \"atk_psn\": 1 if turn.get(f\"{side}_pokemon_state\").get(\"status\") == \"psn\" else 0,\n",
    "                        \"atk_advantage\": 1 if ((\n",
    "                            ((typechart.loc[atk_t1, def_t1] * typechart.loc[atk_t1, def_t2] >= 2.0) or (typechart.loc[atk_t2, def_t1] * typechart.loc[atk_t2, def_t2] >= 2.0)) or\n",
    "                            ((0.0 <= typechart.loc[def_t1, atk_t1] * typechart.loc[def_t1, atk_t2] <= 0.5) or \n",
    "                             (0.0 <= typechart.loc[def_t2, atk_t1] * typechart.loc[def_t2, atk_t2] <= 0.5))) and move.get(\"category\").lower() != \"status\"\n",
    "                        ) else 0,\n",
    "                        f\"status_changed_{side}\": 1 if turn.get(f\"{side}_pokemon_state\").get(\"status\") != \"nostatus\" else 0,\n",
    "                        f\"status_changed_{opponent}\": 1 if turn.get(f\"{opponent}_pokemon_state\").get(\"status\") != \"nostatus\" else 0,\n",
    "                        f\"effects_{side}\": turn.get(f\"{side}_pokemon_state\").get(\"effects\"),\n",
    "                        f\"effects_{opponent}\": turn.get(f\"{opponent}_pokemon_state\").get(\"effects\"),\n",
    "                        f\"{side}_effect_changed\": 1 if turn.get(f\"{side}_pokemon_state\").get(\"effects\") != [\"noeffect\"] else 0,\n",
    "                        f\"{opponent}_effect_changed\": 1 if turn.get(f\"{opponent}_pokemon_state\").get(\"effects\") != [\"noeffect\"] else 0,\n",
    "                        f\"boosted_{side}_atk\": atk_boosts.get(\"atk\", 0),\n",
    "                        f\"boosted_{side}_def\": atk_boosts.get(\"def\", 0),\n",
    "                        f\"boosted_{side}_spa\": atk_boosts.get(\"spa\", 0),\n",
    "                        f\"boosted_{side}_spd\": atk_boosts.get(\"spd\", 0),\n",
    "                        f\"boosted_{side}_spe\": atk_boosts.get(\"spe\", 0),\n",
    "                        f\"boosted_{opponent}_atk\": def_boosts.get(\"atk\", 0),\n",
    "                        f\"boosted_{opponent}_def\": def_boosts.get(\"def\", 0),\n",
    "                        f\"boosted_{opponent}_spa\": def_boosts.get(\"spa\", 0),\n",
    "                        f\"boosted_{opponent}_spd\": def_boosts.get(\"spd\", 0),\n",
    "                        f\"boosted_{opponent}_spe\": def_boosts.get(\"spe\", 0),\n",
    "                        \"atk_hp_pct\": turn.get(f\"{side}_pokemon_state\").get(\"hp_pct\"),\n",
    "                        \"def_hp_pct\": turn.get(f\"{opponent}_pokemon_state\").get(\"hp_pct\"),\n",
    "                    })                            \n",
    "\n",
    "                # Decide who attacks first\n",
    "                p1 = turn_data.get(\"p1\", {\"priority\": 0, \"speed\": 0})\n",
    "                p2 = turn_data.get(\"p2\", {\"priority\": 0, \"speed\": 0})\n",
    "\n",
    "                if p1[\"priority\"] > p2[\"priority\"]:\n",
    "                    first = \"p1\"\n",
    "                elif p2[\"priority\"] > p1[\"priority\"]:\n",
    "                    first = \"p2\"\n",
    "                else:\n",
    "                    first = \"p1\" if p1[\"speed\"] > p2[\"speed\"] else \"p2\" if p2[\"speed\"] > p1[\"speed\"] else \"tie\"\n",
    "\n",
    "                # Assign first attacker to all moves in this turn\n",
    "                for row in turn_moves:\n",
    "                    row[\"first_attacker\"] = first\n",
    "                    move_rows.append(row)\n",
    "\n",
    "    moves_df = pd.DataFrame(move_rows)\n",
    "    moves_df[\"name\"] = moves_df[\"name\"].str.lower().str.strip()\n",
    "\n",
    "    # --- Check for duplicates and NaN values ---\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Checking for duplicates and NaN values...\")\n",
    "\n",
    "        if moves_df.columns.duplicated().any():\n",
    "            print(\"Duplicate columns found:\")\n",
    "            print(moves_df[moves_df.columns[moves_df.columns.duplicated(keep=False)]])\n",
    "\n",
    "        if moves_df.isnull().values.any():\n",
    "            print(\"NaN values found:\")\n",
    "            print(moves_df[moves_df.isnull().any(axis=1)])\n",
    "\n",
    "    return moves_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f28e21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T17:52:58.929712Z",
     "iopub.status.busy": "2025-11-13T17:52:58.929468Z",
     "iopub.status.idle": "2025-11-13T17:54:01.492518Z",
     "shell.execute_reply": "2025-11-13T17:54:01.491365Z"
    },
    "papermill": {
     "duration": 62.57156,
     "end_time": "2025-11-13T17:54:01.494066",
     "exception": false,
     "start_time": "2025-11-13T17:52:58.922506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "moves_df_train = make_moves_df(train_file_path, pokemon_df_train, df_typechart, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b72557",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T17:54:01.505755Z",
     "iopub.status.busy": "2025-11-13T17:54:01.505489Z",
     "iopub.status.idle": "2025-11-13T17:54:01.555570Z",
     "shell.execute_reply": "2025-11-13T17:54:01.554227Z"
    },
    "papermill": {
     "duration": 0.057836,
     "end_time": "2025-11-13T17:54:01.557182",
     "exception": false,
     "start_time": "2025-11-13T17:54:01.499346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(moves_df_train[[def_col for def_col in moves_df_train.columns if def_col.startswith(\"atk_\")]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b71e3e",
   "metadata": {
    "papermill": {
     "duration": 0.005151,
     "end_time": "2025-11-13T17:54:01.568021",
     "exception": false,
     "start_time": "2025-11-13T17:54:01.562870",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Feature engineering (finally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825c59af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T17:54:01.581907Z",
     "iopub.status.busy": "2025-11-13T17:54:01.581548Z",
     "iopub.status.idle": "2025-11-13T17:54:01.619791Z",
     "shell.execute_reply": "2025-11-13T17:54:01.618549Z"
    },
    "papermill": {
     "duration": 0.047171,
     "end_time": "2025-11-13T17:54:01.621772",
     "exception": false,
     "start_time": "2025-11-13T17:54:01.574601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def compute_full_features(moves_df: pd.DataFrame, pokemon_df: pd.DataFrame, jsonl_path: str, verbose: bool) -> pd.DataFrame:\n",
    "    # --- Normalize Pokémon data ---\n",
    "    pokemon_df = pokemon_df.copy()\n",
    "    pokemon_df.columns = pokemon_df.columns.str.lower().str.strip()\n",
    "    pokemon_df[\"name\"] = pokemon_df[\"name\"].str.lower().str.strip()\n",
    "    pokemon_df.set_index(\"name\", inplace=True)\n",
    "\n",
    "    stat_cols = [\"hp\", \"atk\", \"def\", \"spa\", \"spd\", \"spe\"]\n",
    "\n",
    "    # --- Clean moves_df ---\n",
    "    moves_df = moves_df.copy()\n",
    "    moves_df[\"player\"] = moves_df[\"attacker\"]\n",
    "    moves_df[\"atk_pk\"] = moves_df[\"atk_pk\"].str.lower().str.strip()\n",
    "\n",
    "    # --- Move category counts ---\n",
    "    category_counts = (\n",
    "        moves_df.groupby([\"battle_id\", \"player\", \"category\"])\n",
    "        .size()\n",
    "        .unstack(fill_value=0)\n",
    "        .rename(columns={\n",
    "            \"status\": \"num_status_moves\",\n",
    "            \"physical\": \"num_physical_moves\",\n",
    "            \"special\": \"num_special_moves\"\n",
    "        })\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # --- Status changes per player ---\n",
    "    status_changes_p1 = (\n",
    "        moves_df[moves_df[\"player\"] == \"p1\"]\n",
    "        .groupby([\"battle_id\", \"player\"])[\"status_changed_p1\"]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"status_changed_p1\": \"num_status_changes\"})\n",
    "    )\n",
    "\n",
    "    status_changes_p2 = (\n",
    "        moves_df[moves_df[\"player\"] == \"p2\"]\n",
    "        .groupby([\"battle_id\", \"player\"])[\"status_changed_p2\"]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"status_changed_p2\": \"num_status_changes\"})\n",
    "    )\n",
    "\n",
    "    status_changes = pd.concat([status_changes_p1, status_changes_p2], ignore_index=True)\n",
    "\n",
    "    # --- Count how many frz, par, slp, brn, psn status changes per player ---\n",
    "    status_types = [\"frz\", \"par\", \"slp\", \"brn\", \"psn\", \"fnt\"]\n",
    "    status_type_counts = []\n",
    "    for status in status_types:\n",
    "        status_count = (\n",
    "            moves_df[moves_df[\"player\"] == \"p1\"]\n",
    "            .groupby([\"battle_id\", \"player\"])[f\"def_{status}\"]\n",
    "            .sum()\n",
    "            .reset_index()\n",
    "            .rename(columns={f\"def_{status}\": f\"num_{status}_inflicted\"})\n",
    "        )\n",
    "        status_type_counts.append(status_count)\n",
    "\n",
    "        status_count = (\n",
    "            moves_df[moves_df[\"player\"] == \"p2\"]\n",
    "            .groupby([\"battle_id\", \"player\"])[f\"def_{status}\"]\n",
    "            .sum()\n",
    "            .reset_index()\n",
    "            .rename(columns={f\"def_{status}\": f\"num_{status}_inflicted\"})\n",
    "        )\n",
    "        status_type_counts.append(status_count)\n",
    "\n",
    "    status_type_counts_df = pd.concat(status_type_counts, ignore_index=True)\n",
    "\n",
    "    # --- Boosts used per player per feature ---\n",
    "    for stat in [\"atk\", \"def\", \"spa\", \"spd\", \"spe\"]:\n",
    "        moves_df[f\"boosted_{stat}\"] = moves_df.apply(\n",
    "            lambda row: row[f\"boosted_p1_{stat}\"] if row[\"player\"] == \"p1\" else row[f\"boosted_p2_{stat}\"],\n",
    "            axis=1\n",
    "        )\n",
    "    \n",
    "    boosts_summary = (\n",
    "        moves_df.groupby([\"battle_id\", \"player\"])[[f\"boosted_{stat}\" for stat in [\"atk\", \"def\", \"spa\", \"spd\", \"spe\"]]]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "        .rename(columns={f\"boosted_{stat}\": f\"total_boosts_{stat}\" for stat in [\"atk\", \"def\", \"spa\", \"spd\", \"spe\"]})\n",
    "    )\n",
    "\n",
    "    # --- Accuracy ---\n",
    "    acc_df = (\n",
    "        moves_df.groupby([\"battle_id\", \"player\"])[\"accuracy\"]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"accuracy\": \"avg_accuracy\"})\n",
    "    )\n",
    "\n",
    "    # --- Which player had the most priority moves ---\n",
    "    priority_df = (\n",
    "        moves_df.groupby([\"battle_id\", \"player\"])[\"priority\"]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"priority\": \"total_priority\"})\n",
    "    )\n",
    "\n",
    "    # --- Number of moves with accuracy = 1.0 for each player ---\n",
    "    accurate_moves_df = moves_df[moves_df[\"accuracy\"] == 1.0]\n",
    "    hits = (\n",
    "        accurate_moves_df.groupby([\"battle_id\", \"player\"])\n",
    "        .size()\n",
    "        .reset_index()\n",
    "        .rename(columns={0: \"num_accurate_moves\"})\n",
    "    )\n",
    "\n",
    "    # --- Number of moves with accuracy < 1.0 for each player ---\n",
    "    inaccurate_moves_df = moves_df[moves_df[\"accuracy\"] < 1.0]\n",
    "    misses = (\n",
    "        inaccurate_moves_df.groupby([\"battle_id\", \"player\"])\n",
    "        .size()\n",
    "        .reset_index()\n",
    "        .rename(columns={0: \"num_inaccurate_moves\"})\n",
    "    )\n",
    "\n",
    "    # --- Merge Pokémon stats ---\n",
    "    stat_merge = moves_df[[\"battle_id\", \"player\", \"atk_pk\"]]\n",
    "    stat_merge = stat_merge.merge(pokemon_df[stat_cols], left_on=\"atk_pk\", right_index=True, how=\"left\")\n",
    "    stat_merge[stat_cols] = stat_merge[stat_cols].fillna(0)\n",
    "\n",
    "    # --- Mean stats per player ---\n",
    "    mean_stats_df = (\n",
    "        stat_merge.groupby([\"battle_id\", \"player\"])[stat_cols]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .rename(columns={col: f\"mean_{col}\" for col in stat_cols})\n",
    "    )\n",
    "\n",
    "    # --- Variance on stats per player ---\n",
    "    var_stats_df = (\n",
    "        stat_merge.groupby([\"battle_id\", \"player\"])[stat_cols]\n",
    "        .var()\n",
    "        .reset_index()\n",
    "        .rename(columns={col: f\"var_{col}\" for col in stat_cols})\n",
    "    )\n",
    "\n",
    "    # --- Sum stats per player ---\n",
    "    sum_stats_df = (\n",
    "        stat_merge.groupby([\"battle_id\", \"player\"])[stat_cols]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "        .rename(columns={col: f\"sum_{col}\" for col in stat_cols})\n",
    "    )\n",
    "\n",
    "    # --- Sum Damage per player ---\n",
    "    damage_df = (\n",
    "        moves_df.groupby([\"battle_id\", \"player\"])[\"tot_damage\"]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"tot_damage\": \"total_damage\"})\n",
    "    )\n",
    "\n",
    "    # --- Mean Damage per player ---\n",
    "    mean_damage_df = (\n",
    "        moves_df.groupby([\"battle_id\", \"player\"])[\"tot_damage\"]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"tot_damage\": \"mean_damage\"})\n",
    "    )\n",
    "\n",
    "    # --- Effectiveness counts ---\n",
    "    eff_df = moves_df.copy()\n",
    "    eff_df[\"super_effective\"] = eff_df[\"se_move\"]\n",
    "    eff_df[\"not_effective\"] = eff_df[\"pe_move\"]\n",
    "    eff_df[\"neutral\"] = 1 - (eff_df[\"se_move\"] + eff_df[\"pe_move\"] + eff_df[\"ne_move\"])\n",
    "\n",
    "    eff_counts = (\n",
    "        eff_df.groupby([\"battle_id\", \"player\"])[[\"super_effective\", \"neutral\", \"not_effective\"]]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "        .rename(columns={\n",
    "            \"super_effective\": \"num_super_effective\",\n",
    "            \"neutral\": \"num_neutral\",\n",
    "            \"not_effective\": \"num_not_effective\"\n",
    "        })\n",
    "    )\n",
    "\n",
    "    # --- Total pokemon switches per player ---\n",
    "    moves_df = moves_df.sort_values(by=[\"battle_id\", \"turn\"])\n",
    "    moves_df[\"prev_atk_pk\"] = moves_df.groupby([\"battle_id\", \"player\"])[\"atk_pk\"].shift(1)\n",
    "    \n",
    "    moves_df[\"is_switch\"] = (moves_df[\"atk_pk\"] != moves_df[\"prev_atk_pk\"]) & (moves_df[\"prev_atk_pk\"].notna())\n",
    "    switches_df = (\n",
    "        moves_df.groupby([\"battle_id\", \"player\"])[\"is_switch\"]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"is_switch\": \"num_switches\"})\n",
    "    )\n",
    "\n",
    "    # --- Estimate drops hp_pct (actual hits) ---\n",
    "    moves_df[\"prev_def_hp_pct\"] = moves_df.groupby([\"battle_id\", \"defender\"])[\"def_hp_pct\"].shift(1)\n",
    "    moves_df[\"has_been_hit\"] = (\n",
    "        (moves_df[\"def_hp_pct\"] < moves_df[\"prev_def_hp_pct\"]) &\n",
    "        (moves_df[\"prev_def_hp_pct\"].notna())\n",
    "    )\n",
    "\n",
    "    actual_damage_df = (\n",
    "        moves_df.groupby([\"battle_id\", \"defender\"])[\"has_been_hit\"]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"defender\": \"player\", \"has_been_hit\": \"num_times_hit\"})\n",
    "    )\n",
    "\n",
    "    # --- Pokemon has regenerated HP (e.g., via Recover) if pokemon has not been switched ---\n",
    "    moves_df[\"prev_atk_hp_pct\"] = moves_df.groupby([\"battle_id\", \"player\"])[\"atk_hp_pct\"].shift(1)\n",
    "    moves_df[\"has_regenerated\"] = (\n",
    "        (moves_df[\"atk_hp_pct\"] > moves_df[\"prev_atk_hp_pct\"]) &\n",
    "        (moves_df[\"prev_atk_hp_pct\"].notna()) &\n",
    "        (~moves_df[\"is_switch\"])\n",
    "    )\n",
    "\n",
    "    regen_df = (\n",
    "        moves_df.groupby([\"battle_id\", \"player\"])[\"has_regenerated\"]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"has_regenerated\": \"num_regens\"})\n",
    "    )\n",
    "\n",
    "    # --- Total KO ---\n",
    "    kill_df = (\n",
    "        moves_df.groupby([\"battle_id\", \"player\"])[\"ko\"]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"ko\": \"ko_count\"})\n",
    "    )\n",
    "\n",
    "    # --- Type advantage moves ---\n",
    "    adv_df = (\n",
    "        moves_df.groupby([\"battle_id\", \"player\"])[\"atk_advantage\"]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"atk_advantage\": \"num_advantage_moves\"})\n",
    "    )\n",
    "\n",
    "    # --- Count occurrences where player attacks first ---\n",
    "    first_attacker_counts = (\n",
    "        moves_df[moves_df[\"first_attacker\"] == moves_df[\"player\"]]\n",
    "        .groupby([\"battle_id\", \"player\"])\n",
    "        .size()\n",
    "        .reset_index()\n",
    "        .rename(columns={0: \"num_first_attacks\"})\n",
    "    )\n",
    "\n",
    "    # --- p2 attacks first count ---\n",
    "    second_attacker_counts = (\n",
    "        moves_df[moves_df[\"first_attacker\"] != moves_df[\"player\"]]\n",
    "        .groupby([\"battle_id\", \"player\"])\n",
    "        .size()\n",
    "        .reset_index()\n",
    "        .rename(columns={0: \"num_second_attacks\"})\n",
    "    )\n",
    "\n",
    "    # --- Count how many times effects changed per player ---\n",
    "    moves_df[\"effect_changed\"] = moves_df.apply(\n",
    "        lambda row: row[\"p1_effect_changed\"] if row[\"player\"] == \"p1\" else row[\"p2_effect_changed\"],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    effects_summary = (\n",
    "        moves_df.groupby([\"battle_id\", \"player\"])[[\"effect_changed\"]]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "        .rename(columns={\n",
    "            \"effect_changed\": \"num_effects_changed\"\n",
    "        })\n",
    "    )\n",
    "\n",
    "    # --- Merge all player-level features ---\n",
    "    player_df = (\n",
    "        category_counts\n",
    "        .merge(acc_df, on=[\"battle_id\", \"player\"], how=\"outer\")\n",
    "        .merge(mean_stats_df, on=[\"battle_id\", \"player\"], how=\"outer\")\n",
    "        .merge(sum_stats_df, on=[\"battle_id\", \"player\"], how=\"outer\")\n",
    "        .merge(var_stats_df, on=[\"battle_id\", \"player\"], how=\"outer\")\n",
    "        .merge(eff_counts, on=[\"battle_id\", \"player\"], how=\"outer\")\n",
    "        .merge(kill_df, on=[\"battle_id\", \"player\"], how=\"outer\")\n",
    "        .merge(status_changes, on=[\"battle_id\", \"player\"], how=\"outer\")\n",
    "        .merge(status_type_counts_df, on=[\"battle_id\", \"player\"], how=\"outer\")\n",
    "        .merge(damage_df, on=[\"battle_id\", \"player\"], how=\"outer\")\n",
    "        .merge(boosts_summary, on=[\"battle_id\", \"player\"], how=\"outer\")\n",
    "        .merge(priority_df, on=[\"battle_id\", \"player\"], how=\"outer\")\n",
    "        .merge(adv_df, on=[\"battle_id\", \"player\"], how=\"outer\")\n",
    "        .merge(first_attacker_counts, on=[\"battle_id\", \"player\"], how=\"outer\")\n",
    "        .merge(second_attacker_counts, on=[\"battle_id\", \"player\"], how=\"outer\")\n",
    "        .merge(hits, on=[\"battle_id\", \"player\"], how=\"outer\")\n",
    "        .merge(misses, on=[\"battle_id\", \"player\"], how=\"outer\")\n",
    "        .merge(effects_summary, on=[\"battle_id\", \"player\"], how=\"outer\")\n",
    "        .merge(switches_df, on=[\"battle_id\", \"player\"], how=\"outer\")\n",
    "        .merge(regen_df, on=[\"battle_id\", \"player\"], how=\"outer\")\n",
    "        .merge(actual_damage_df, on=[\"battle_id\", \"player\"], how=\"outer\")\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "    player_df = (\n",
    "        player_df\n",
    "        .groupby([\"battle_id\", \"player\"])\n",
    "        .sum(numeric_only=True)\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "\n",
    "    dupes = player_df.groupby([\"battle_id\", \"player\"]).size()\n",
    "    dupes = dupes[dupes > 1]\n",
    "    print(dupes)\n",
    "\n",
    "    # Reset index after pivoting\n",
    "    battle_df = (\n",
    "        player_df.pivot(index=\"battle_id\", columns=\"player\")\n",
    "        .sort_index(axis=1)\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Separate out the pivoted columns\n",
    "    pivot_cols = battle_df.columns.drop(\"battle_id\")\n",
    "    battle_df.columns = [\"battle_id\"] + [f\"{player}_{feature}\" for feature, player in pivot_cols]\n",
    "\n",
    "    # --- Add diffs of stats ---\n",
    "    battle_df[\"mean_spe_diff\"] = battle_df[\"p1_mean_spe\"] - battle_df[\"p2_mean_spe\"]\n",
    "    battle_df[\"mean_atk_diff\"] = battle_df[\"p1_mean_atk\"] - battle_df[\"p2_mean_atk\"]\n",
    "    battle_df[\"mean_def_diff\"] = battle_df[\"p1_mean_def\"] - battle_df[\"p2_mean_def\"]\n",
    "    battle_df[\"mean_spa_diff\"] = battle_df[\"p1_mean_spa\"] - battle_df[\"p2_mean_spa\"]\n",
    "    battle_df[\"mean_spd_diff\"] = battle_df[\"p1_mean_spd\"] - battle_df[\"p2_mean_spd\"]\n",
    "    battle_df[\"mean_hp_diff\"] = battle_df[\"p1_mean_hp\"] - battle_df[\"p2_mean_hp\"]\n",
    "\n",
    "    battle_df[\"var_atk_diff\"] = battle_df[\"p1_var_atk\"] - battle_df[\"p2_var_atk\"]\n",
    "    battle_df[\"var_def_diff\"] = battle_df[\"p1_var_def\"] - battle_df[\"p2_var_def\"]\n",
    "    battle_df[\"var_spa_diff\"] = battle_df[\"p1_var_spa\"] - battle_df[\"p2_var_spa\"]\n",
    "    battle_df[\"var_spd_diff\"] = battle_df[\"p1_var_spd\"] - battle_df[\"p2_var_spd\"]\n",
    "    battle_df[\"var_spe_diff\"] = battle_df[\"p1_var_spe\"] - battle_df[\"p2_var_spe\"]\n",
    "    battle_df[\"var_hp_diff\"] = battle_df[\"p1_var_hp\"] - battle_df[\"p2_var_hp\"]\n",
    "\n",
    "    # --- Add diff switches ---\n",
    "    battle_df[\"diff_num_switches\"] = battle_df[\"p1_num_switches\"] - battle_df[\"p2_num_switches\"]\n",
    "\n",
    "    print(battle_df.columns.tolist())\n",
    "\n",
    "    # --- Add player_won labels ---\n",
    "    labels = []\n",
    "    with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            battle = json.loads(line)\n",
    "            labels.append({\n",
    "                \"battle_id\": battle.get(\"battle_id\"),\n",
    "                \"player_won\": battle.get(\"player_won\", None)\n",
    "            })\n",
    "    labels_df = pd.DataFrame(labels)\n",
    "\n",
    "    # --- Merge winner label into final df ---\n",
    "    battle_df = battle_df.merge(labels_df, on=\"battle_id\", how=\"left\")\n",
    "\n",
    "    # SANITY CHECKS\n",
    "    if verbose:\n",
    "        print(\"Performing sanity checks on final DataFrame...\")\n",
    "\n",
    "        # --- Ensure both players exist per battle ---\n",
    "        all_battles = moves_df[\"battle_id\"].unique()\n",
    "        expected_players = [\"p1\", \"p2\"]\n",
    "        full_index = pd.MultiIndex.from_product([all_battles, expected_players], names=[\"battle_id\", \"player\"])\n",
    "        player_df = player_df.set_index([\"battle_id\", \"player\"]).reindex(full_index).reset_index().fillna(0)\n",
    "\n",
    "        # --- Check that both players are in all battles ---\n",
    "        expected_battles = set(moves_df[\"battle_id\"].unique())\n",
    "        actual_battles = set(battle_df[\"battle_id\"].unique())\n",
    "        missing_battles = expected_battles - actual_battles\n",
    "        if missing_battles:\n",
    "            print(f\"WARNING: Missing battles in final DataFrame: {missing_battles}\")\n",
    "\n",
    "        # --- Check that there are no duplicate columns ---\n",
    "        if battle_df.columns.duplicated().any():\n",
    "            duplicated_cols = battle_df.columns[battle_df.columns.duplicated()].unique()\n",
    "            print(f\"WARNING: Duplicate columns found in final DataFrame: {duplicated_cols.tolist()}\")\n",
    "\n",
    "        # --- Check for NaN values ---\n",
    "        if battle_df.isnull().values.any():\n",
    "            print(\"WARNING: NaN values found in final DataFrame.\")\n",
    "            print(battle_df[battle_df.isnull().any(axis=1)])\n",
    "\n",
    "        # --- Check duplicate merges ---\n",
    "        if battle_df.duplicated(subset=[\"battle_id\"]).any():\n",
    "            print(\"WARNING: Duplicate battle_id entries found in final DataFrame.\")\n",
    "            print(battle_df[battle_df.duplicated(subset=[\"battle_id\"], keep=False)])\n",
    "\n",
    "        print(\"Data is sane (unlike me)\")\n",
    "\n",
    "    return battle_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c72808",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T17:54:01.634099Z",
     "iopub.status.busy": "2025-11-13T17:54:01.633788Z",
     "iopub.status.idle": "2025-11-13T17:54:24.858284Z",
     "shell.execute_reply": "2025-11-13T17:54:24.856980Z"
    },
    "papermill": {
     "duration": 23.2325,
     "end_time": "2025-11-13T17:54:24.860045",
     "exception": false,
     "start_time": "2025-11-13T17:54:01.627545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = compute_full_features(moves_df_train, pokemon_df_train, train_file_path, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3462260c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T17:54:24.873123Z",
     "iopub.status.busy": "2025-11-13T17:54:24.872666Z",
     "iopub.status.idle": "2025-11-13T17:54:24.930590Z",
     "shell.execute_reply": "2025-11-13T17:54:24.929869Z"
    },
    "papermill": {
     "duration": 0.065806,
     "end_time": "2025-11-13T17:54:24.931891",
     "exception": false,
     "start_time": "2025-11-13T17:54:24.866085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 180)\n",
    "display(train_df.head())\n",
    "\n",
    "# see dimensionality of final training dataframe\n",
    "print(f\"Training DataFrame shape: {train_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e06763",
   "metadata": {
    "papermill": {
     "duration": 0.005603,
     "end_time": "2025-11-13T17:54:24.944173",
     "exception": false,
     "start_time": "2025-11-13T17:54:24.938570",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3551da3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T17:54:24.956702Z",
     "iopub.status.busy": "2025-11-13T17:54:24.956459Z",
     "iopub.status.idle": "2025-11-13T17:54:27.434854Z",
     "shell.execute_reply": "2025-11-13T17:54:27.433615Z"
    },
    "papermill": {
     "duration": 2.486738,
     "end_time": "2025-11-13T17:54:27.436589",
     "exception": false,
     "start_time": "2025-11-13T17:54:24.949851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Imports (a lot of them) ---\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, RandomizedSearchCV, GridSearchCV, StratifiedKFold, HalvingGridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5065d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T17:54:27.470147Z",
     "iopub.status.busy": "2025-11-13T17:54:27.469858Z",
     "iopub.status.idle": "2025-11-13T17:54:27.486142Z",
     "shell.execute_reply": "2025-11-13T17:54:27.484980Z"
    },
    "papermill": {
     "duration": 0.024892,
     "end_time": "2025-11-13T17:54:27.487865",
     "exception": false,
     "start_time": "2025-11-13T17:54:27.462973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = train_df.drop(columns=[\"battle_id\", \"player_won\"])\n",
    "y = train_df[\"player_won\"]\n",
    "\n",
    "# Split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4da54f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T17:54:27.502092Z",
     "iopub.status.busy": "2025-11-13T17:54:27.501775Z",
     "iopub.status.idle": "2025-11-13T17:54:27.527758Z",
     "shell.execute_reply": "2025-11-13T17:54:27.526761Z"
    },
    "papermill": {
     "duration": 0.0344,
     "end_time": "2025-11-13T17:54:27.529151",
     "exception": false,
     "start_time": "2025-11-13T17:54:27.494751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3200ffe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T17:54:27.542809Z",
     "iopub.status.busy": "2025-11-13T17:54:27.542567Z",
     "iopub.status.idle": "2025-11-13T17:56:32.960557Z",
     "shell.execute_reply": "2025-11-13T17:56:32.959616Z"
    },
    "papermill": {
     "duration": 125.431879,
     "end_time": "2025-11-13T17:56:32.967538",
     "exception": false,
     "start_time": "2025-11-13T17:54:27.535659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Training singular models for a different Stacking Classifier later ---\n",
    "\n",
    "# Define parameter grid\n",
    "logreg_param_grid = {\n",
    "    \"C\": [0.01, 0.1, 1, 10],\n",
    "    \"penalty\": [\"l2\"],\n",
    "    \"solver\": [\"liblinear\", \"saga\"] # saga does not converge, leaving it for exploration\n",
    "}\n",
    "\n",
    "# Model\n",
    "logreg = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# Halving Grid Search\n",
    "logreg_search = HalvingGridSearchCV(\n",
    "    estimator=logreg,\n",
    "    param_grid=logreg_param_grid,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Define parameter grid\n",
    "rf_param_grid = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"max_depth\": [None, 5, 10],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "    \"min_samples_leaf\": [1, 2],\n",
    "    \"max_features\": [\"sqrt\", \"log2\"]\n",
    "}\n",
    "\n",
    "# Model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Halving Grid Search\n",
    "rf_search = HalvingGridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=rf_param_grid,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=5,\n",
    "    verbose=0,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "\n",
    "logreg_search.fit(X_train, y_train)\n",
    "rf_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Logistic Regression best score:\", logreg_search.best_score_)\n",
    "print(\"Best params:\", logreg_search.best_params_)\n",
    "\n",
    "print(\"Random Forest best score:\", rf_search.best_score_)\n",
    "print(\"Best params:\", rf_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fcbd70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T17:56:32.986830Z",
     "iopub.status.busy": "2025-11-13T17:56:32.986436Z",
     "iopub.status.idle": "2025-11-13T18:08:28.650281Z",
     "shell.execute_reply": "2025-11-13T18:08:28.649291Z"
    },
    "papermill": {
     "duration": 715.681615,
     "end_time": "2025-11-13T18:08:28.658036",
     "exception": false,
     "start_time": "2025-11-13T17:56:32.976421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define parameter distributions\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"max_depth\": [3, 4, 5],\n",
    "    \"learning_rate\": [0.05, 0.1],\n",
    "    \"subsample\": [0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.8, 1.0],\n",
    "    \"min_child_weight\": [1, 3],\n",
    "    \"gamma\": [0, 0.1, 0.2],\n",
    "    \"reg_alpha\": [0, 0.1, 0.5],\n",
    "    \"reg_lambda\": [1, 1.5, 2]\n",
    "}\n",
    "\n",
    "# 2. Set up the model\n",
    "xgb = XGBClassifier(use_label_encoder=False, \n",
    "                    eval_metric=\"logloss\", \n",
    "                    random_state=42, \n",
    "                    objective=\"binary:logistic\"\n",
    "                    )\n",
    "\n",
    "# 3. Run Halving Grid Search (normal GridSearchCV takes WAY too long)\n",
    "random_search = HalvingGridSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=5,\n",
    "    verbose=0,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Check train dataset dimensions\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "\n",
    "# 4. Results\n",
    "print(\"Best parameters:\", random_search.best_params_)\n",
    "print(\"Best CV score:\", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd54000",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T18:08:28.673342Z",
     "iopub.status.busy": "2025-11-13T18:08:28.672986Z",
     "iopub.status.idle": "2025-11-13T18:08:29.466649Z",
     "shell.execute_reply": "2025-11-13T18:08:29.465470Z"
    },
    "papermill": {
     "duration": 0.803543,
     "end_time": "2025-11-13T18:08:29.468543",
     "exception": false,
     "start_time": "2025-11-13T18:08:28.665000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_xgb = random_search.best_estimator_\n",
    "best_xgb.fit(X_train, y_train)\n",
    "y_pred = best_xgb.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "model=best_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee67efb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T18:08:29.486313Z",
     "iopub.status.busy": "2025-11-13T18:08:29.485502Z",
     "iopub.status.idle": "2025-11-13T18:09:09.357854Z",
     "shell.execute_reply": "2025-11-13T18:09:09.357210Z"
    },
    "papermill": {
     "duration": 39.888203,
     "end_time": "2025-11-13T18:09:09.365644",
     "exception": false,
     "start_time": "2025-11-13T18:08:29.477441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- StackingClassfier with XGB, RandomForest and CatBoost, tuned LogisticRegression as final estimator ---\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# --- Define CatBoost model ---\n",
    "catboost_model = CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    verbose=0,  # suppress training output\n",
    "    loss_function='Logloss',\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "stacked_model2 = StackingClassifier(\n",
    "    estimators=[\n",
    "        (\"xgb\", best_xgb),\n",
    "        (\"rf\", rf_search.best_estimator_),\n",
    "        (\"catboost\", catboost_model)\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(**logreg_search.best_params_),\n",
    "    cv=5,\n",
    "    passthrough=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "stacked_model2.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = stacked_model2.predict(X_val)\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2683e60",
   "metadata": {
    "papermill": {
     "duration": 0.007218,
     "end_time": "2025-11-13T18:09:09.381744",
     "exception": false,
     "start_time": "2025-11-13T18:09:09.374526",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Checking feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29bb8c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T18:09:09.396642Z",
     "iopub.status.busy": "2025-11-13T18:09:09.396381Z",
     "iopub.status.idle": "2025-11-13T18:12:08.682627Z",
     "shell.execute_reply": "2025-11-13T18:12:08.681141Z"
    },
    "papermill": {
     "duration": 179.302509,
     "end_time": "2025-11-13T18:12:08.691072",
     "exception": false,
     "start_time": "2025-11-13T18:09:09.388563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "# Calibrate the stacking classifier -> probas can increase metrics\n",
    "calibrated_stack = CalibratedClassifierCV(estimator=stacked_model2, \n",
    "                                          method=\"sigmoid\", \n",
    "                                          cv=5,\n",
    "                                        )\n",
    "calibrated_stack.fit(X_train, y_train)\n",
    "\n",
    "# Predict calibrated probabilities\n",
    "calibrated_probs = calibrated_stack.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Tune decision threshold for F1 score\n",
    "best_thresh = 0.5\n",
    "best_score = 0\n",
    "\n",
    "for t in np.linspace(0.3, 0.7, 100):\n",
    "    preds = (calibrated_probs > t).astype(int)\n",
    "    score = f1_score(y_val, preds)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_thresh = t\n",
    "\n",
    "print(\"Best threshold:\", best_thresh)\n",
    "print(\"Best F1 score:\", best_score)\n",
    "\n",
    "# Include accuracy at best threshold\n",
    "final_preds = (calibrated_probs > best_thresh).astype(int)\n",
    "final_accuracy = accuracy_score(y_val, final_preds)\n",
    "print(\"Final Accuracy at best threshold:\", final_accuracy)\n",
    "\n",
    "# ROC AUC score\n",
    "roc_auc = roc_auc_score(y_val, calibrated_probs)\n",
    "print(\"ROC AUC Score:\", roc_auc)\n",
    "\n",
    "final_preds = (calibrated_probs > best_thresh).astype(int)\n",
    "print(\"Final Predictions:\", final_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf82c0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T18:12:08.707898Z",
     "iopub.status.busy": "2025-11-13T18:12:08.707631Z",
     "iopub.status.idle": "2025-11-13T18:12:09.061823Z",
     "shell.execute_reply": "2025-11-13T18:12:09.060727Z"
    },
    "papermill": {
     "duration": 0.365232,
     "end_time": "2025-11-13T18:12:09.063795",
     "exception": false,
     "start_time": "2025-11-13T18:12:08.698563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Set up dimensionality reduction with PCA ---\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pca = PCA(n_components=\"mle\")\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "print(f\"Original shape: {X_scaled.shape}, PCA reduced shape: {X_pca.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812f1458",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T18:12:09.079994Z",
     "iopub.status.busy": "2025-11-13T18:12:09.079698Z",
     "iopub.status.idle": "2025-11-13T18:16:33.849447Z",
     "shell.execute_reply": "2025-11-13T18:16:33.848579Z"
    },
    "papermill": {
     "duration": 264.779365,
     "end_time": "2025-11-13T18:16:33.850826",
     "exception": false,
     "start_time": "2025-11-13T18:12:09.071461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "X_train_pca, X_val_pca, y_train_pca, y_val_pca = train_test_split(X_pca, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "sm_pca = stacked_model2.fit(X_train_pca, y_train_pca)\n",
    "cs_pca = calibrated_stack.fit(X_train_pca, y_train_pca)\n",
    "\n",
    "# Evaluate\n",
    "preds_sm2 = stacked_model2.predict(X_val_pca)\n",
    "print(\"Accuracy (stacked_model2):\", accuracy_score(y_val_pca, preds_sm2))\n",
    "\n",
    "preds_cal_sm2 = calibrated_stack.predict(X_val_pca)\n",
    "print(\"Accuracy (calibrated_stack):\", accuracy_score(y_val_pca, preds_cal_sm2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5848d3dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T18:16:33.867521Z",
     "iopub.status.busy": "2025-11-13T18:16:33.867222Z",
     "iopub.status.idle": "2025-11-13T18:16:33.878341Z",
     "shell.execute_reply": "2025-11-13T18:16:33.877332Z"
    },
    "papermill": {
     "duration": 0.021487,
     "end_time": "2025-11-13T18:16:33.880065",
     "exception": false,
     "start_time": "2025-11-13T18:16:33.858578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# diff in accuracy\n",
    "print(\"Final accuracy of calibrated_stack before PCA:\", final_accuracy)\n",
    "print(\"Final accuracy of stacked_model2 before PCA:\", accuracy_score(y_val, y_pred))\n",
    "\n",
    "diff_accuracy = accuracy_score(y_val_pca, preds_cal_sm2) - final_accuracy\n",
    "diff_accuracy_sm = accuracy_score(y_val_pca, preds_sm2) - accuracy_score(y_val, y_pred)\n",
    "\n",
    "print(\"Difference in accuracy after PCA (calibrated_stack):\", diff_accuracy)\n",
    "print(\"Difference in accuracy after PCA (stacked_model2):\", diff_accuracy_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beac6acd",
   "metadata": {
    "papermill": {
     "duration": 0.006963,
     "end_time": "2025-11-13T18:16:33.894761",
     "exception": false,
     "start_time": "2025-11-13T18:16:33.887798",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. Creating the Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742691c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T18:16:33.910347Z",
     "iopub.status.busy": "2025-11-13T18:16:33.910040Z",
     "iopub.status.idle": "2025-11-13T18:17:21.815915Z",
     "shell.execute_reply": "2025-11-13T18:17:21.815021Z"
    },
    "papermill": {
     "duration": 47.915534,
     "end_time": "2025-11-13T18:17:21.817369",
     "exception": false,
     "start_time": "2025-11-13T18:16:33.901835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare test features\n",
    "pokemon_df_test = extract_unique_pokemon_no_ids(test_file_path)\n",
    "moves_df_test = make_moves_df(test_file_path, pokemon_df_test, df_typechart, verbose=False)\n",
    "test_df = compute_full_features(moves_df_test, pokemon_df_test, test_file_path, verbose=False)\n",
    "\n",
    "X_test_raw = test_df.drop(columns=[\"battle_id\", \"player_won\"])\n",
    "\n",
    "# Apply same scaling and PCA\n",
    "X_test_scaled = scaler.transform(X_test_raw)  # use the same scaler as training\n",
    "X_test_pca = pca.transform(X_test_scaled)     # use the same PCA as training\n",
    "\n",
    "# Make predictions\n",
    "print(\"Generating predictions on the test set...\")\n",
    "test_predictions_cs = calibrated_stack.predict(X_test_pca)\n",
    "\n",
    "# Create submission DataFrame\n",
    "submission_df_cs = pd.DataFrame({\n",
    "    \"battle_id\": test_df[\"battle_id\"],\n",
    "    \"player_won\": test_predictions_cs\n",
    "})\n",
    "\n",
    "# Trial with stacked_model2 gave the same public lb score, we chose to select the calibrated_stack model because it was stronger in all trials\n",
    "# test_predictions_sm = stacked_model2.predict(X_test_pca)\n",
    "# submission_df_sm = pd.DataFrame({\n",
    "#     \"battle_id\": test_df[\"battle_id\"],\n",
    "#     \"player_won\": test_predictions_sm\n",
    "# })\n",
    "\n",
    "# 5. Save to CSV\n",
    "submission_df_cs.to_csv(\"submission_cs.csv\", index=False)\n",
    "# submission_df_sm.to_csv(\"submission_sm.csv\", index=False)\n",
    "\n",
    "print(\"\\n'submission_cs.csv' file created successfully!\")\n",
    "# print(\"\\n'submission_sm.csv' file created successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13033998,
     "sourceId": 107555,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1490.331327,
   "end_time": "2025-11-13T18:17:24.747925",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-13T17:52:34.416598",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
